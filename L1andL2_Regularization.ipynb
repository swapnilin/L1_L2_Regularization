{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's import the libraries\n",
    "\n",
    "* When in doubt regarding which Scikit-Learn module something belongs to, refer to this <a href=\"http://scikit-learn.org/stable/modules/classes.html\" target=\"_blank\">documentation page</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Pandas for DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn for easier visualization\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Pickle for saving model files\n",
    "import pickle\n",
    "\n",
    "# Import Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import RandomForestClassifier and GradientBoostingClassifer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function for creating model pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's read in the analytical base table you saved at the end of Module 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('analytical_base_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data is a limited resource.** Let's start by splitting our data into training and testing sets. \n",
    "\n",
    "We can spend some of it to train your model, some of it to test, or evaluate your model.\n",
    "\n",
    "Having a true \"unseen\" test dataset helps us prevent overfit models and ultimately select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Variable\n",
    "y = df.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input features/Independant variables/Predictors\n",
    "x = df.drop('status', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test split function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pass in the argument **test_size=0.2** to set aside 20% of our observations for the test set.\n",
    "* Pass in **random_state=123** to set the random state for replicable results. (It can be any number)\n",
    "* Also pass in the argument **stratify=abt.status** in order to make sure the target variable's| classes are balanced in each subset of data! This is stratified random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 123, stratify =df.status, test_size=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11254 11254 2814 2814\n"
     ]
    }
   ],
   "source": [
    "#verify\n",
    "print(len(x_train),len(y_train),len(x_test),len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's standardize the data (Mean = 0, std = 1) using standard scalar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the independant variables in the train set\n",
    "X_train = sc.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the independant variables in the test set\n",
    "X_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualise the scaled data using a histogram\n",
    "plt.hist(X_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we don't have to scale the 'status' (target) variable because the values are only 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <code style=\"color:Green\">1. Logistic Regression</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Penalty type - L1 regularized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"color:crimson\">For Linear regression:\n",
    "\n",
    "* **L1** regularization is called **Lasso regression**\n",
    "* **L2** regularization is called **Ridge regression** </code>\n",
    "\n",
    "\n",
    "For logistic regression, we'll simply call it L1 and L2-regularized logistic regression. By default, LogisticRegression uses the L2 penalty.\n",
    "\n",
    "We will work out the L1 penalty first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of parameters we need to consider when using machine learning algorithms.\n",
    "\n",
    "* Model parameters<br>\n",
    "* Hyperparamters\n",
    "\n",
    "Model parameters are learned directly from the training data while hyperparameters are not (so we can tune them initially)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's list the tunable hyperparameters for  ùêø1 regularized logistic regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember**: We don't need to tune all the parameters. For regularized logistic regression, the most impactful hyperparameter is the strength of the penalty **'C'**\n",
    "\n",
    "<code style=\"color:crimson\">For Lasso, Ridge, and Elastic-Net algorithms, this is alpha.</code>\n",
    "\n",
    "**Strength of the penalty**<br>\n",
    "* C is the inverse of regularization strength.<br>\n",
    "* That means higher values of C means weaker penalties.<br>\n",
    "* C is a positive value, typically between 0 and 1000. The default is 1.0<br>\n",
    "\n",
    "For **C**, let's try values between 0.001 and 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001\n",
      "Accuracy score: 0.789\n",
      "[[2134    7]\n",
      " [ 588   85]] \n",
      "\n",
      "C = 0.005\n",
      "Accuracy score: 0.796\n",
      "[[2006  135]\n",
      " [ 440  233]] \n",
      "\n",
      "C = 0.01\n",
      "Accuracy score: 0.812\n",
      "[[1985  156]\n",
      " [ 372  301]] \n",
      "\n",
      "C = 0.05\n",
      "Accuracy score: 0.83\n",
      "[[1960  181]\n",
      " [ 296  377]] \n",
      "\n",
      "C = 0.1\n",
      "Accuracy score: 0.838\n",
      "[[1964  177]\n",
      " [ 280  393]] \n",
      "\n",
      "C = 0.5\n",
      "Accuracy score: 0.842\n",
      "[[1966  175]\n",
      " [ 270  403]] \n",
      "\n",
      "C = 1\n",
      "Accuracy score: 0.842\n",
      "[[1966  175]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 5\n",
      "Accuracy score: 0.842\n",
      "[[1966  175]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 10\n",
      "Accuracy score: 0.842\n",
      "[[1966  175]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 50\n",
      "Accuracy score: 0.842\n",
      "[[1965  176]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 100\n",
      "Accuracy score: 0.842\n",
      "[[1965  176]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 500\n",
      "Accuracy score: 0.842\n",
      "[[1966  175]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 1000\n",
      "Accuracy score: 0.842\n",
      "[[1965  176]\n",
      " [ 269  404]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for L1 penalty regularized Logistic Regression, use solver='liblinear' to prevent the error\n",
    "\n",
    "for n in [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]:\n",
    "    modellr1 = LogisticRegression(C=n,penalty='l1', solver='liblinear')\n",
    "    modellr1.fit(X_train, y_train)\n",
    "    y_pred = modellr1.predict(X_test)\n",
    "    confusion_matrix(y_test,y_pred)\n",
    "    print('C =',n)\n",
    "    print('Accuracy score:', np.round(accuracy_score(y_test, y_pred),3))\n",
    "    print(confusion_matrix(y_test, y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We can note that increasing penalty beyond certain point does not change the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Penalty type - L2 regularized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for penalty L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001\n",
      "Accuracy score: 0.781\n",
      "[[2054   87]\n",
      " [ 529  144]] \n",
      "\n",
      "C = 0.005\n",
      "Accuracy score: 0.813\n",
      "[[2016  125]\n",
      " [ 402  271]] \n",
      "\n",
      "C = 0.01\n",
      "Accuracy score: 0.819\n",
      "[[1987  154]\n",
      " [ 354  319]] \n",
      "\n",
      "C = 0.05\n",
      "Accuracy score: 0.835\n",
      "[[1965  176]\n",
      " [ 289  384]] \n",
      "\n",
      "C = 0.1\n",
      "Accuracy score: 0.838\n",
      "[[1968  173]\n",
      " [ 284  389]] \n",
      "\n",
      "C = 0.5\n",
      "Accuracy score: 0.842\n",
      "[[1966  175]\n",
      " [ 270  403]] \n",
      "\n",
      "C = 1\n",
      "Accuracy score: 0.842\n",
      "[[1966  175]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 5\n",
      "Accuracy score: 0.842\n",
      "[[1966  175]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 10\n",
      "Accuracy score: 0.842\n",
      "[[1966  175]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 50\n",
      "Accuracy score: 0.842\n",
      "[[1965  176]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 100\n",
      "Accuracy score: 0.842\n",
      "[[1965  176]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 500\n",
      "Accuracy score: 0.842\n",
      "[[1965  176]\n",
      " [ 269  404]] \n",
      "\n",
      "C = 1000\n",
      "Accuracy score: 0.842\n",
      "[[1965  176]\n",
      " [ 269  404]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for L2 penalty regularized Logistic Regression\n",
    "\n",
    "for n in [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]:\n",
    "    modellr2 = LogisticRegression(C=n,penalty='l2')\n",
    "    modellr2.fit(X_train, y_train)\n",
    "    y2_pred = modellr2.predict(X_test)\n",
    "    confusion_matrix(y_test,y2_pred)\n",
    "    print('C =',n)\n",
    "    print('Accuracy score:', np.round(accuracy_score(y_test, y2_pred),3))\n",
    "    print(confusion_matrix(y_test, y2_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We can note that increasing penalty beyond certain point does not change the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <code style=\"color:Green\">2. Random Forest</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's list the tunable hyperparameters for Random Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For random forests,<br> \n",
    "* The first hyperparameter to tune is **n_estimators.** We will try 100 and 200.<br>\n",
    "* The second one is **max_features.** Let's try - 'auto', 'sqrt', and 0.33.<br>\n",
    "* The third one is **min_samples_leaf.** Let's try - 1, 3, 5, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 100 m = auto l = 1 Accuracy score: 0.974\n",
      "[[2123   18]\n",
      " [  56  617]] \n",
      "\n",
      "n = 100 m = auto l = 3 Accuracy score: 0.969\n",
      "[[2121   20]\n",
      " [  67  606]] \n",
      "\n",
      "n = 100 m = auto l = 5 Accuracy score: 0.967\n",
      "[[2118   23]\n",
      " [  70  603]] \n",
      "\n",
      "n = 100 m = auto l = 10 Accuracy score: 0.964\n",
      "[[2115   26]\n",
      " [  74  599]] \n",
      "\n",
      "n = 100 m = sqrt l = 1 Accuracy score: 0.973\n",
      "[[2122   19]\n",
      " [  56  617]] \n",
      "\n",
      "n = 100 m = sqrt l = 3 Accuracy score: 0.969\n",
      "[[2121   20]\n",
      " [  68  605]] \n",
      "\n",
      "n = 100 m = sqrt l = 5 Accuracy score: 0.966\n",
      "[[2118   23]\n",
      " [  72  601]] \n",
      "\n",
      "n = 100 m = sqrt l = 10 Accuracy score: 0.965\n",
      "[[2115   26]\n",
      " [  72  601]] \n",
      "\n",
      "n = 100 m = 0.33 l = 1 Accuracy score: 0.975\n",
      "[[2126   15]\n",
      " [  54  619]] \n",
      "\n",
      "n = 100 m = 0.33 l = 3 Accuracy score: 0.971\n",
      "[[2122   19]\n",
      " [  63  610]] \n",
      "\n",
      "n = 100 m = 0.33 l = 5 Accuracy score: 0.968\n",
      "[[2122   19]\n",
      " [  70  603]] \n",
      "\n",
      "n = 100 m = 0.33 l = 10 Accuracy score: 0.965\n",
      "[[2114   27]\n",
      " [  71  602]] \n",
      "\n",
      "n = 200 m = auto l = 1 Accuracy score: 0.974\n",
      "[[2122   19]\n",
      " [  55  618]] \n",
      "\n",
      "n = 200 m = auto l = 3 Accuracy score: 0.967\n",
      "[[2118   23]\n",
      " [  70  603]] \n",
      "\n",
      "n = 200 m = auto l = 5 Accuracy score: 0.966\n",
      "[[2117   24]\n",
      " [  71  602]] \n",
      "\n",
      "n = 200 m = auto l = 10 Accuracy score: 0.964\n",
      "[[2113   28]\n",
      " [  73  600]] \n",
      "\n",
      "n = 200 m = sqrt l = 1 Accuracy score: 0.973\n",
      "[[2120   21]\n",
      " [  55  618]] \n",
      "\n",
      "n = 200 m = sqrt l = 3 Accuracy score: 0.969\n",
      "[[2121   20]\n",
      " [  68  605]] \n",
      "\n",
      "n = 200 m = sqrt l = 5 Accuracy score: 0.967\n",
      "[[2119   22]\n",
      " [  72  601]] \n",
      "\n",
      "n = 200 m = sqrt l = 10 Accuracy score: 0.964\n",
      "[[2115   26]\n",
      " [  74  599]] \n",
      "\n",
      "n = 200 m = 0.33 l = 1 Accuracy score: 0.976\n",
      "[[2126   15]\n",
      " [  53  620]] \n",
      "\n",
      "n = 200 m = 0.33 l = 3 Accuracy score: 0.971\n",
      "[[2122   19]\n",
      " [  63  610]] \n",
      "\n",
      "n = 200 m = 0.33 l = 5 Accuracy score: 0.97\n",
      "[[2121   20]\n",
      " [  65  608]] \n",
      "\n",
      "n = 200 m = 0.33 l = 10 Accuracy score: 0.965\n",
      "[[2113   28]\n",
      " [  71  602]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's create a loop\n",
    "    \n",
    "for n in [100, 200]:\n",
    "     for m in ['auto', 'sqrt', 0.33]:\n",
    "            for l in [1, 3, 5, 10]:\n",
    "                modelrf = RandomForestClassifier(n_estimators=n, max_features=m, min_samples_leaf=l)\n",
    "                modelrf.fit(X_train, y_train)\n",
    "                y3_pred = modelrf.predict(X_test)  \n",
    "                print('n =',n, 'm =',m , 'l =',l, 'Accuracy score:', np.round(accuracy_score(y_test, y3_pred),3))\n",
    "                print(confusion_matrix(y_test, y3_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <code style=\"color:Green\">3. Boosted Trees - Gradient Boosting</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's list the tunable hyperparameters for Gradient Boosting algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For boosted trees,<br> \n",
    "* The first hyperparameter to tune is **n_estimators.** We will try 100 and 200<br>\n",
    "* The second one is **learning_rate.** Let's try - 0.05, 0.1 and 0.2<br>\n",
    "* The third one is **max_depth.** Let's try - 1, 3, 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1 m = 0.05 l = 1 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 1 m = 0.05 l = 3 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 1 m = 0.05 l = 5 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 1 m = 0.1 l = 1 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 1 m = 0.1 l = 3 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 1 m = 0.1 l = 5 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 1 m = 0.2 l = 1 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 1 m = 0.2 l = 3 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 1 m = 0.2 l = 5 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 3 m = 0.05 l = 1 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 3 m = 0.05 l = 3 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 3 m = 0.05 l = 5 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 3 m = 0.1 l = 1 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 3 m = 0.1 l = 3 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 3 m = 0.1 l = 5 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 3 m = 0.2 l = 1 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 3 m = 0.2 l = 3 Accuracy score: 0.941\n",
      "[[2103   38]\n",
      " [ 127  546]] \n",
      "\n",
      "n = 3 m = 0.2 l = 5 Accuracy score: 0.964\n",
      "[[2114   27]\n",
      " [  73  600]] \n",
      "\n",
      "n = 5 m = 0.05 l = 1 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 5 m = 0.05 l = 3 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 5 m = 0.05 l = 5 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 5 m = 0.1 l = 1 Accuracy score: 0.761\n",
      "[[2141    0]\n",
      " [ 673    0]] \n",
      "\n",
      "n = 5 m = 0.1 l = 3 Accuracy score: 0.848\n",
      "[[2128   13]\n",
      " [ 415  258]] \n",
      "\n",
      "n = 5 m = 0.1 l = 5 Accuracy score: 0.963\n",
      "[[2114   27]\n",
      " [  76  597]] \n",
      "\n",
      "n = 5 m = 0.2 l = 1 Accuracy score: 0.833\n",
      "[[2105   36]\n",
      " [ 435  238]] \n",
      "\n",
      "n = 5 m = 0.2 l = 3 Accuracy score: 0.941\n",
      "[[2077   64]\n",
      " [ 101  572]] \n",
      "\n",
      "n = 5 m = 0.2 l = 5 Accuracy score: 0.966\n",
      "[[2114   27]\n",
      " [  68  605]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's create a loop\n",
    "\n",
    "for n in [1, 3, 5]:\n",
    "    for m in [0.05, 0.1, 0.2]:\n",
    "        for l in [1, 3, 5]:\n",
    "            modelgb = GradientBoostingClassifier(n_estimators=n, learning_rate=m, max_depth=l)\n",
    "            modelgb.fit(X_train, y_train)\n",
    "            y4_pred = modelgb.predict(X_test)  \n",
    "            print('n =',n, 'm =',m , 'l =',l, 'Accuracy score:', np.round(accuracy_score(y_test, y4_pred),3))\n",
    "            print(confusion_matrix(y_test, y4_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, from the 4 types of algorithms, **Random Forest** has given us the best score.\n",
    "\n",
    "Accuracy score of 0.976  for  n = 200, m = 0.33, and l = 1 \n",
    "\n",
    "**Accuracy** is simply the percent of observations correctly classified by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only calculating the accuracy is not always the best way to evaluate a classification model. Another way is to also calculate the **AUROC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receiver Operating Characteristic (ROC) curve & Area Under ROC (AUROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict_proba generates two columns and we need the second column for the probability values.\n",
    "\n",
    "\n",
    "predict_proba() produces output of shape (N, k) where N is the number of datapoints and k is the number of classes you're trying to classify. It seems you have two classes and hence you have 2 columns. Say your labels(classes) are [\"healthy\", \"diabetes\"], if a datapoint is predicted to have 80% chance of being diabetic and consequently 20% chance of being healthy, then your output row for that point will be [0.2, 0.8] to reflect these probabilities. In general you can go through the predicted array and get probabilities for the k-th class with model.predict_proba(X)[:,k-1]\n",
    "\n",
    "**This will change for multi-label classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = modellr1.predict_proba(X_test)[:,1]\n",
    "y2_proba = modellr2.predict_proba(X_test)[:,1]\n",
    "y3_proba = modelrf.predict_proba(X_test)[:,1]\n",
    "y4_proba = modelgb.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a ROC curve from y_test and pred\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "fpr2, tpr2, thresholds = roc_curve(y_test, y2_proba)\n",
    "fpr3, tpr3, thresholds = roc_curve(y_test, y3_proba)\n",
    "fpr4, tpr4, thresholds = roc_curve(y_test, y4_proba)\n",
    "\n",
    "plt.plot(fpr, tpr, label= 'lr1')\n",
    "plt.plot(fpr2, tpr2, label = 'lr2')\n",
    "plt.plot(fpr3, tpr3, label = 'rf')\n",
    "plt.plot(fpr4, tpr4, label = 'gb')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  As we can see, the area under curve is maximum for the Random Forest classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression L1: 0.893\n",
      "Logistic Regression L2: 0.893\n",
      "Random Forest: 0.987\n",
      "Gradient Boosting: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression L1:',np.round(roc_auc_score(y_test, y_proba),3))\n",
    "print('Logistic Regression L2:',np.round(roc_auc_score(y_test, y2_proba),3))\n",
    "print('Random Forest:',np.round(roc_auc_score(y_test, y3_proba),3))\n",
    "print('Gradient Boosting:',np.round(roc_auc_score(y_test, y4_proba),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also, the AUROC score is maximum for the Random Forest Classifer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this case Random Forest classifer is our clear WINNER!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
